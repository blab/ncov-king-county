{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e16f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import baltic as bt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import time\n",
    "#import pymc3\n",
    "import math\n",
    "import arviz as az\n",
    "#from hpd import hpd\n",
    "import scipy.stats as stats\n",
    "from io import StringIO\n",
    "import altair as alt\n",
    "from altair import datum\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a60aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "current_date = str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa63df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_migration_rates_mascot(log_file_path):\n",
    "    \n",
    "    mig_rates_dict = {\"sample\":[]}\n",
    "    \n",
    "    with open(log_file_path, \"r\") as infile:\n",
    "        line_number = 0\n",
    "        for line in infile:\n",
    "            line_number += 1\n",
    "            if not line.startswith(\"#\"):  # log combiner will sometimes put the entire xml at the start of the log file\n",
    "                # use the first line to find the migration rate columns\n",
    "                \n",
    "                if \"sample\" in line.lower():\n",
    "                    all_cols = line.split(\"\\t\")\n",
    "                    migration_column_indices = []   # list to store column indices\n",
    "                    mig_rates_key = {}   # dictionary to store the column index to map to column name\n",
    "                    counter = 0\n",
    "                    for i in range(len(all_cols)):\n",
    "                        col = all_cols[i]\n",
    "                        if col == \"immigrationRate.1\":\n",
    "                            counter = counter + 1\n",
    "                        if (\"immigrationRate\" in col) and (counter <2):\n",
    "                            migration_column_indices.append(i)\n",
    "                    \n",
    "                    # make an empty dictionary to store migration rates and generate dictionary to convert index to name\n",
    "                    for m in migration_column_indices:\n",
    "                        name = line.split(\"\\t\")[m]\n",
    "                        mig_rates_key[m] = name\n",
    "                        mig_rates_dict[name] = []\n",
    "                    \n",
    "                # read in actual parameter estimates and store in dictionary\n",
    "                else:\n",
    "                    sample = line.split(\"\\t\")[0]\n",
    "                    mig_rates_dict[\"sample\"].append(sample)\n",
    "\n",
    "                    for index in migration_column_indices:\n",
    "                        name = mig_rates_key[index]\n",
    "                        mig_rates_dict[name].append(line.split(\"\\t\")[index])\n",
    "                \n",
    "                \n",
    "    return(mig_rates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22274bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_file_path = \"../../mascot_glm/results/glm_mcc_map_subsampledkc_clusters_combined_new_3000.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_rates = read_in_migration_rates_mascot(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5900052",
   "metadata": {},
   "outputs": [],
   "source": [
    "mig_df = pd.DataFrame.from_dict(migration_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin_percent = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ddffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mig_df = pd.DataFrame.from_dict(migration_rates)\n",
    "print(len(mig_df))\n",
    "\n",
    "rows_to_remove = int(len(mig_df)* burnin_percent)\n",
    "mig_df = mig_df.iloc[rows_to_remove:]\n",
    "\n",
    "print(len(mig_df))\n",
    "#mig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62097c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe that summarizes the 95% HPD estimate with mean for each deme and interval \n",
    "def generate_summary_mr_df(input_df):\n",
    "    \n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    for i in input_df.columns.tolist():\n",
    "        if \"immigrationRate\" in i:\n",
    "            #deme = i.split(\"_\")[1]\n",
    "            interval = i.split(\".\")[1]\n",
    "            next_interval = int(interval)+1\n",
    "            local_series = input_df[i].astype('float').to_numpy()\n",
    "            mean_log = local_series.mean()\n",
    "            mean_linear = 10**mean_log\n",
    "            hpd_95 = az.hdi(local_series, 0.95)\n",
    "            lower_hpd_log_95 = hpd_95[0]\n",
    "            lower_hpd_linear_95 = math.exp(lower_hpd_log_95)\n",
    "            upper_hpd_log_95 = hpd_95[1]\n",
    "            upper_hpd_linear_95 = math.exp(upper_hpd_log_95)\n",
    "            hpd_50 = az.hdi(local_series, 0.50)\n",
    "            lower_hpd_log_50 = hpd_50[0]\n",
    "            lower_hpd_linear_50 = math.exp(lower_hpd_log_50)\n",
    "            upper_hpd_log_50 = hpd_50[1]\n",
    "            upper_hpd_linear_50 = math.exp(upper_hpd_log_50)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                local_df = pd.DataFrame.from_dict({\"interval\":interval, \"mean_mr_log\":mean_log,\"mean_mr_linear\":mean_linear, \n",
    "                                                   \"upper_hpd_log_95\":upper_hpd_log_95,\"lower_hpd_log_95\":[lower_hpd_log_95], \n",
    "                                                   \"upper_hpd_log_50\":upper_hpd_log_50,\"lower_hpd_log_50\":lower_hpd_log_50,\n",
    "                                                   \"upper_hpd_linear\":upper_hpd_linear_95,\"lower_hpd_linear\":lower_hpd_linear_95,\n",
    "                                                   \"upper_hpd_linear_50\":upper_hpd_linear_50,\"lower_hpd_linear_50\":lower_hpd_linear_50})\n",
    "                new_df = new_df.append(local_df)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047962bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_summary = generate_summary_mr_df(mig_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b749208",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_summary['days'] = mr_summary.interval.astype(int) *14\n",
    "mr_summary['date'] = dt.strptime(\"2022-03-06\",  \"%Y-%m-%d\") - mr_summary.days.map(timedelta)\n",
    "mr_summary.date = mr_summary.date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793914ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = alt.Chart(mr_summary).mark_area(interpolate='monotone').encode(\n",
    "    alt.X('date:T', axis=alt.Axis(title=\"Date\", grid=False)),\n",
    "    alt.Y('lower_hpd_linear_50',axis=alt.Axis(title=\"introductions\", grid=False)),\n",
    "    alt.Y2('upper_hpd_linear_50' )\n",
    ").properties(\n",
    "    width=850,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "band = alt.Chart(mr_summary).mark_area(\n",
    "    opacity=0.3, interpolate='monotone'\n",
    ").encode(\n",
    "    alt.X('date:T', axis=alt.Axis(title=\"Date\", grid=False)),\n",
    "    alt.Y('lower_hpd_linear'),\n",
    "    alt.Y2('upper_hpd_linear')\n",
    ").properties(\n",
    "    width=850,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "band + line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b7322",
   "metadata": {},
   "source": [
    "## Now plotting Ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_Ne_changes_mascot(log_file_path):\n",
    "    \n",
    "    Ne_skyline_dict = {\"sample\":[]}\n",
    "    \n",
    "    with open(log_file_path, \"r\") as infile:\n",
    "        line_number = 0\n",
    "        for line in infile:\n",
    "            line_number += 1\n",
    "            if not line.startswith(\"#\"):  # log combiner will sometimes put the entire xml at the start of the log file\n",
    "                # use the first line to find the migration rate columns\n",
    "            \n",
    "            # use the first line to find the migration rate columns\n",
    "                if \"posterior\" in line:\n",
    "                    all_cols = line.split(\"\\t\")\n",
    "                    Ne_column_indices = []   # list to store column indices\n",
    "                    Nes_key = {}   # dictionary to store the column index to map to column name\n",
    "\n",
    "                    for i in range(len(all_cols)):\n",
    "                        col = all_cols[i]\n",
    "                        if \"Ne.\" in col:\n",
    "                            Ne_column_indices.append(i)\n",
    "\n",
    "                    # make an empty dictionary to store Nes and generate dictionary to convert index to name\n",
    "                    for n in Ne_column_indices:\n",
    "                        name = line.split(\"\\t\")[n]\n",
    "                        deme = name.split(\".\")[1]# the syntax here is \"NeLog.state01\" where 0 is deme and 1 is interval 1\n",
    "                        interval = name.split(\".\")[2]\n",
    "                       \n",
    "                        Nes_key[n] = name\n",
    "                        Ne_skyline_dict[name] = []\n",
    "\n",
    "\n",
    "                # read in actual parameter estimates and store in dictionary\n",
    "                else:\n",
    "                    sample = line.split(\"\\t\")[0]\n",
    "                    Ne_skyline_dict[\"sample\"].append(sample)\n",
    "\n",
    "                    for index in Ne_column_indices:\n",
    "                        name = Nes_key[index]\n",
    "                        Ne_skyline_dict[name].append(line.split(\"\\t\")[index])\n",
    "                    \n",
    "                \n",
    "    return(Ne_skyline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e14e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne_skyline = read_in_Ne_changes_mascot(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513edfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe that summarizes the 95% HPD estimate with mean for each deme and interval \n",
    "def generate_summary_df(input_df):\n",
    "    \n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    for i in input_df.columns.tolist():\n",
    "        if \"Ne\" in i:\n",
    "            deme = i.split(\".\")[1]\n",
    "            #print(deme)\n",
    "            interval = i.split(\".\")[2]\n",
    "            #print(interval)\n",
    "            #print(i)\n",
    "            next_interval = int(interval)+1\n",
    "            local_series = input_df[i].astype('float').to_numpy()\n",
    "            #print(local_series)\n",
    "            mean_log = local_series.mean()\n",
    "            mean_linear = 10**mean_log\n",
    "            hpd_95 = az.hdi(local_series, 0.95)\n",
    "            lower_hpd_log_95 = hpd_95[0]\n",
    "            lower_hpd_linear_95 = 10**lower_hpd_log_95\n",
    "            upper_hpd_log_95 = hpd_95[1]\n",
    "            upper_hpd_linear_95 = 10**upper_hpd_log_95\n",
    "            hpd_50 = az.hdi(local_series, 0.50)\n",
    "            lower_hpd_log_50 = hpd_50[0]\n",
    "            lower_hpd_linear_50 = 10**lower_hpd_log_50\n",
    "            upper_hpd_log_50 = hpd_50[1]\n",
    "            upper_hpd_linear_50 = 10**upper_hpd_log_50\n",
    "            \n",
    "            try:\n",
    "                next_local_series = input_df[\"Ne\"+\".\"+ str(deme) +\".\" + str(next_interval)].astype('float').to_numpy()\n",
    "                diff_series = np.subtract(local_series, next_local_series)\n",
    "                #print(local_series)\n",
    "                #print(next_local_series)\n",
    "                #print(diff_series)\n",
    "                diff_mean_log = diff_series.mean()\n",
    "                diff_hpd_95 = az.hdi(diff_series, 0.95)\n",
    "                diff_lower_hpd_log_95 = diff_hpd_95[0]\n",
    "                diff_lower_hpd_linear_95 = math.exp(diff_lower_hpd_log_95)\n",
    "                diff_upper_hpd_log_95 = diff_hpd_95[1]\n",
    "                diff_upper_hpd_linear_95 = math.exp(diff_upper_hpd_log_95)\n",
    "                diff_hpd_50 = az.hdi(diff_series, 0.50)\n",
    "                diff_lower_hpd_log_50 = diff_hpd_50[0]\n",
    "                diff_lower_hpd_linear_50 = math.exp(diff_lower_hpd_log_50)\n",
    "                diff_upper_hpd_log_50 = diff_hpd_50[1]\n",
    "                diff_upper_hpd_linear_50 = math.exp(diff_upper_hpd_log_50)\n",
    "            except KeyError:\n",
    "                pass   \n",
    "            \n",
    "            try:\n",
    "                local_df = pd.DataFrame.from_dict({\"deme\":deme, \"interval\":interval, \"mean_Ne_log\":mean_log,\"mean_Ne_linear\":mean_linear, \n",
    "                                                   \"upper_hpd_log_95\":upper_hpd_log_95,\"lower_hpd_log_95\":[lower_hpd_log_95], \n",
    "                                                   \"upper_hpd_log_50\":upper_hpd_log_50,\"lower_hpd_log_50\":lower_hpd_log_50,\n",
    "                                                   \"upper_hpd_linear\":upper_hpd_linear_95,\"lower_hpd_linear\":lower_hpd_linear_95,\n",
    "                                                   \"diff_mean_Ne_log\":diff_mean_log, \n",
    "                                                   \"diff_upper_hpd_log_95\":diff_upper_hpd_log_95,\"diff_lower_hpd_log_95\":diff_lower_hpd_log_95, \n",
    "                                                   \"diff_upper_hpd_log_50\":diff_upper_hpd_log_50,\"diff_lower_hpd_log_50\":diff_lower_hpd_log_50,\n",
    "                                                   \"diff_upper_hpd_linear\":diff_upper_hpd_linear_95,\"diff_lower_hpd_linear\":diff_lower_hpd_linear_95,\n",
    "                                                   \"diff_upper_hpd_linear_50\":diff_upper_hpd_linear_50,\"diff_lower_hpd_linear_50\":diff_lower_hpd_linear_50})\n",
    "                new_df = new_df.append(local_df)\n",
    "                #print(new_df)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896bbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne_df = pd.DataFrame.from_dict(Ne_skyline)\n",
    "print(len(Ne_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db39b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_summary = generate_summary_df(Ne_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a5c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = alt.Chart(ne_summary).mark_area(interpolate='monotone').encode(\n",
    "    alt.X('interval:O'),\n",
    "    alt.Y('lower_hpd_log_50',axis=alt.Axis(title=\"Effective Population Size\")),\n",
    "    alt.Y2('upper_hpd_log_50' ),\n",
    "    color=alt.Color('deme:N')\n",
    ").properties(\n",
    "    width=900,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "band = alt.Chart(ne_summary).mark_area(\n",
    "    opacity=0.3, interpolate='monotone'\n",
    ").encode(\n",
    "    alt.X('interval:O'),\n",
    "    alt.Y('lower_hpd_log_95',axis=alt.Axis(title=\"Effective Population Size\")),\n",
    "    alt.Y2('upper_hpd_log_95'),\n",
    "    color=alt.Color('deme:N')\n",
    ").properties(\n",
    "    width=900,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "band + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58835335",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ne_summary\n",
    "test['days'] = test.interval.astype(int) \n",
    "test['date'] = dt.strptime(\"2022-03-06\",  \"%Y-%m-%d\") - test.days.map(timedelta)\n",
    "#test.date = test.date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.date >\"2020-01-31\"]\n",
    "test.to_csv(\"../data-files/ne_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = alt.Chart(test).mark_area(interpolate='monotone').encode(\n",
    "    alt.X('date:T', axis=alt.Axis(title=\"Date\", grid=False)),\n",
    "    alt.Y('lower_hpd_log_50',axis=alt.Axis(title=\"Effective Population Size\", grid=False)),#,scale=alt.Scale(domain=(0, 13))),\n",
    "    alt.Y2('upper_hpd_log_50' ),\n",
    "    color=alt.Color('deme:N')\n",
    ").properties(\n",
    "    width=950,\n",
    "    height=300\n",
    ")#.transform_filter(\n",
    "  #  (datum.upper_hpd_log_50 < 50)\n",
    "#)\n",
    "\n",
    "band = alt.Chart(test).mark_area(\n",
    "    opacity=0.3, interpolate='monotone'\n",
    ").encode(\n",
    "    alt.X('date:T', axis=alt.Axis(title=\"Date\", grid=False)),\n",
    "    alt.Y('lower_hpd_log_95'),#axis=None),#, scale=alt.Scale(domain=(0, 13))),\n",
    "    alt.Y2('upper_hpd_log_95'),\n",
    "    color=alt.Color('deme:N', legend=None)\n",
    ").properties(\n",
    "    width=950,\n",
    "    height=300\n",
    ")#.transform_filter(\n",
    " #   (datum.upper_hpd_log_95 < 50)\n",
    "#)\n",
    "\n",
    "band + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = band +line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744262cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#highlighting important NPIs in WA\n",
    "data = {'date': [ \"2020-03-23\", \"2020-06-01\", \"2020-11-18\", \"2021-02-14\"], 'event':[ \"Stay at home\", \"Stay at home lifted\", \"Closing restaurants\", \"Reopening restaurants\"]}\n",
    "\n",
    "npidf = pd.DataFrame(data)\n",
    "npidf.date = pd.to_datetime(npidf.date)\n",
    "\n",
    "rule = alt.Chart(npidf).mark_rule(\n",
    "    color=\"black\",\n",
    "    strokeWidth=2, \n",
    "    opacity = 0.3\n",
    ").encode(\n",
    "    alt.X('date:T', axis=alt.Axis(title=None))\n",
    ").properties(\n",
    "    width=1550,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "text = alt.Chart(npidf).mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=2,\n",
    "    dy=-135,\n",
    "    size=11\n",
    ").encode(\n",
    "    alt.X('date:T',axis=alt.Axis(title=None)),\n",
    "    text='event',\n",
    "    color=alt.value('#000000')\n",
    ").properties(\n",
    "    width=1550,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb031d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne = (base + text + rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne.save(\"../figures/subsampled_map_ne.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
